HazyVision-python
=================

Used to send data to our 2014 FRC robot during autonomous.
We are creating a goalie robot for the 2014 FIRST FRC game during the offseason, and it will have two arms that can be stuck up for blocking. In order to control the robot during autonomous, we need to be able to tell the robot whether it needs to drive left or right in the goalie zone, and which arm to raise.
After seeing CheesyVision during the season, we realized how effective OpenCV is and began experimenting.

The included files will allow you to use a webcam to find a paddle on the screen.
It will be looking for one of two paddles, whose colors can be updated in "config.py". This script will have you press Enter, show the video feed with a yellow box drawn in the middle. After pressing Enter to begin the countdown, you have 5 seconds to position the paddle over the yellow square for sampling. After this has been done, the video will freeze until you press Enter again, at which point you will once again have 5 seconds to position the second paddle.
hazyVision.py will read the values that were generated by "config.py" and then search the screen for the largest objects with that color. It will then draw a red or green square around that object for viewing.
The blue boxes that are currently drawn are going to be part of the checking to see whether the paddles are in that region for robot movement, and it will then send a value to the robot (between 0 and 31) in order to have scaling speed depending how far over it is in the camera.

ToDo
=================
Add links to install openCV and numPy
Clean up scripts
Config.py:
	run constantly and sample when button pressed
	Update window that is used to display (remove excess outside)
hazyVision.py:
	check which square is larger so that it will override background noise
	Test, test, test!


Changelog
=================
1.1
Scales speed based on location in image

1.0
Transmits to robot.
config.py working, writes to file
hazyVision.py working